import os
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Transformers ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
os.environ["TRANSFORMERS_OFFLINE"] = "1"

class KCBERTSentimentAnalyzer:
    """ë‹¨ì¼ KCBERT ê¸°ë°˜ ê°ì„± ë¶„ì„ê¸° (3í´ë˜ìŠ¤) - ì‹±ê¸€í†¤ íŒ¨í„´"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(KCBERTSentimentAnalyzer, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not KCBERTSentimentAnalyzer._initialized:
            self.model_name = "beomi/kcbert-base"
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, local_files_only=True)
                self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, local_files_only=True)
                KCBERTSentimentAnalyzer._initialized = True
            except Exception as e:
                print("ğŸ”´ ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:", e)
                print("âš ï¸ Hugging Face ëª¨ë¸ ìºì‹œê°€ ì—†ê±°ë‚˜ ì¸í„°ë„·ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                self.model = None
                self.tokenizer = None
    
    def predict(self, text):
        if self.model is None or self.tokenizer is None:
            print("âš ï¸ ê°ì„± ë¶„ì„ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return 1, 0.0  # ì¤‘ë¦½(1) ë°˜í™˜, ì‹ ë¢°ë„ 0
            
        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
        outputs = self.model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        sentiment = torch.argmax(probs, dim=1).item()
        confidence = probs.max().item()
        return sentiment, confidence  # 0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì • 